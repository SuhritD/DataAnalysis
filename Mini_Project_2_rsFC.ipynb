{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcKD2GNpI7vU"
      },
      "outputs": [],
      "source": [
        "#################################################################################\n",
        "# Project fMRI - Resting state study\n",
        "#\n",
        "# Aliénor Clerfayt, Suhrit Duttagupta, Jean-Charles Nicolas and Emilie Pons\n",
        "#################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "We import libraries and the results of the 10 ICA component analysis from the database to apply on the rsMRI volumes. \n"
      ],
      "metadata": {
        "id": "XiOKaWBaWlt2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bjTkmzQ9pitB",
        "outputId": "ef39cb7e-b980-41d9-bb39-ce04ad0a4f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.11-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.30.0,>=1.29.11\n",
            "  Downloading botocore-1.29.11-py3-none-any.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 35.3 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.11->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.11->boto3) (1.15.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.26.11 botocore-1.29.11 jmespath-1.0.1 s3transfer-0.6.0 urllib3-1.26.12\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nilearn\n",
            "  Downloading nilearn-0.9.2-py3-none-any.whl (9.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.6 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nibabel>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.15 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.21.6)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.0.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from nilearn) (4.9.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->nilearn) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->nilearn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->nilearn) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->nilearn) (3.1.0)\n",
            "Installing collected packages: urllib3, nilearn\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.12\n",
            "    Uninstalling urllib3-1.26.12:\n",
            "      Successfully uninstalled urllib3-1.26.12\n",
            "Successfully installed nilearn-0.9.2 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        }
      ],
      "source": [
        "###############################\n",
        "# Installing required libraries\n",
        "###############################\n",
        "%matplotlib inline\n",
        "!pip install boto3\n",
        "import os\n",
        "import boto3\n",
        "from botocore.handlers import disable_signing\n",
        "import re \n",
        "import numpy as np\n",
        "client = boto3.client('s3')\n",
        "client.meta.events.register('choose-signer.s3.*', disable_signing)\n",
        "!pip install nilearn\n",
        "from nilearn import plotting\n",
        "from nilearn import image,masking\n",
        "from scipy.fft import fft,fftfreq\n",
        "from scipy.fftpack import fftshift\n",
        "from scipy.signal import spectrogram\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "##################################################################\n",
        "# Import results from the 10 -Independent Component Analysis (ICA) \n",
        "# of Amsterdam Open MRI Collection to use in our study\n",
        "# Details Published in Nature in 2021\n",
        "##################################################################\n",
        "import requests\n",
        "URL=\"https://neurovault.org/media/images/7104/comp-\"\n",
        "if not os.path.exists('0tstat.nii.gz'):\n",
        "  for i in range(10):\n",
        "    response = requests.get(URL+str(i)+'_desc-dualreg_tstat.nii.gz')\n",
        "    open(str(i)+'tstat.nii.gz', \"wb\").write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################\n",
        "# Importing Fourier transform functions and ploting functions\n",
        "###############################################################\n",
        "from scipy.fft import fft,fftfreq\n",
        "from scipy.fftpack import fftshift\n",
        "from scipy.signal import spectrogram\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Uy72VaMJvCWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions for Masking\n",
        "We define functions to build binary masks from coordinates of the ICA component maps. "
      ],
      "metadata": {
        "id": "cUzBHKlzXf9c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "936LOQx-LFNW"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "import nibabel as nb\n",
        "import nilearn.masking as masking\n",
        "\n",
        "###################################\n",
        "# Define functions to create masks\n",
        "###################################\n",
        "def get_mm_coord(img,coords):\n",
        "    x,y,z = coords\n",
        "    shape, affine = img.shape[:3], img.affine\n",
        "    coords = np.array(np.meshgrid(*(range(i) for i in shape),\n",
        "                                  indexing='ij'))\n",
        "    coords = np.rollaxis(coords, 0, len(shape) + 1)\n",
        "    mm_coords = nb.affines.apply_affine(affine, coords)\n",
        "    return np.round(mm_coords[x,y,z]).astype(int)\n",
        "\n",
        "def get_volIdx(img,mm_coords):\n",
        "    x,y,z = mm_coords\n",
        "    inv_aff = np.linalg.inv(img.affine)\n",
        "    idx_real = nb.affines.apply_affine(inv_aff,np.transpose(np.array([x,y,z])))\n",
        "    return np.floor(idx_real).astype(int)\n",
        "\n",
        "def build_mask_from_coord(img_,coords):\n",
        "    x,y,z = coords\n",
        "    img_segbool = np.zeros(np.array(img_.shape))\n",
        "    img_segbool[x,y,z]=1\n",
        "    return nb.Nifti1Image(img_segbool,  affine=img_.affine)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Functions for Signal**\n",
        "The time-series from the masked MRI data will undergo drift removal and bandpass filtering. We will then take the Fourier Transformation to obtain the high and low frequencies from the signal. \n"
      ],
      "metadata": {
        "id": "sbfVJWvnJn8M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V81ntHXKLFNZ"
      },
      "outputs": [],
      "source": [
        "import scipy, scipy.signal\n",
        "from scipy.signal import butter, filtfilt\n",
        "##############################################\n",
        "# Define a butter filter for high or low band\n",
        "##############################################\n",
        "\n",
        "def butter_lowpass(cutoff, fs, order = 5):\n",
        "    fnyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / fnyq\n",
        "    b, a = butter(order, normal_cutoff, btype = 'low', output = 'ba', fs = 2, analog = False)\n",
        "    return b, a\n",
        "def butter_highpass(cutoff, fs, order = 5):\n",
        "    fnyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / fnyq\n",
        "    b, a = butter(order, normal_cutoff, btype='high', output = 'ba', fs = 2, analog = False)\n",
        "    return b, a\n",
        "def butter_filter(data, cutoff, fs, order=5, filtype=''):\n",
        "    if filtype.lower() == 'lowpass':\n",
        "        b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    elif filtype.lower() == 'highpass':\n",
        "        b, a = butter_highpass(cutoff, fs, order=order)        \n",
        "        \n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def filt(ts):\n",
        "  dt = 2 # Use Time of repetition (TR) of the Echo planar image (EPI) acquisition\n",
        "  fs = 1/dt # Sampling Frequency\n",
        "  time_vec= np.array(range(0,len(ts)*dt,dt))\n",
        "  #Removing drift using curve fitting\n",
        "  def test_func(x,a0,a,b,c,d):\n",
        "        return a0+a*x+b*x**2+c*x**3+d*x**4\n",
        " \n",
        " \n",
        "  params,params_cov = scipy.optimize.curve_fit(test_func,time_vec,ts)\n",
        "  a0,a,b,c,d = params[0],params[1],params[2],params[3],params[4]\n",
        "  drift = [test_func(x,a0,a,b,c,d) for x in time_vec] # Calculate the drift\n",
        "  yf = ts-drift  # We remove the drift\n",
        "\n",
        "#####################\n",
        "# High pass Filtering\n",
        "#####################\n",
        "  order = 6\n",
        "  fc = 0.01  # desired cutoff frequency of the filter, Hz\n",
        "  fs = 1/dt\n",
        "  # Get the filter coefficients so we can check its frequency response.\n",
        "  b,a = butter_highpass(fc, fs, order) #Numerator (b) and denominator (a) polynomials of the IIR filter. \n",
        "  y_filt = butter_filter(yf, fc, fs, order, 'highpass')\n",
        "\n",
        "#####################\n",
        "# Low pass Filtering\n",
        "#####################\n",
        "  fc = 0.15 \n",
        "  order = 5\n",
        "  fs = 1/dt\n",
        "  # Get the filter coefficients so we can check its frequency response.\n",
        "  b,a = butter_lowpass(fc, fs, order) #Numerator (b) and denominator (a) polynomials of the IIR filter.\n",
        "  y_tfilt = butter_filter(y_filt, fc, fs, order, 'lowpass')\n",
        "  return y_tfilt\n",
        "\n",
        "############################\n",
        "# Fast Fourier Transform\n",
        "############################\n",
        "\n",
        "def FFT(signal,freq):\n",
        "  #FFT of the filtered signal and returning the required frequencies\n",
        "  dt = 2\n",
        "  N = 3*len(signal)//10 # number of FFT points (length of signal)\n",
        "  Y = fft(signal/signal.mean(),N) # calculate the FFT\n",
        "  tyF = fftfreq(N, dt)[:N//2]\n",
        "  if freq =='low':\n",
        "    return abs(Y[0:N//4])\n",
        "  elif freq =='high':\n",
        "    return abs(Y[N//4:N//2])\n",
        "  elif freq =='all':\n",
        "    return abs(Y[:N//2])\n",
        "########################################\n",
        "# Define correlation between two signals\n",
        "########################################\n",
        "def corr(Y1,Y2):\n",
        "  correlate = scipy.stats.pearsonr(Y1,Y2)\n",
        "  return correlate[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "Using the top 100 values from the ICA components, we apply the binary masks on the volumes and correlate the high frequency and low frequency signals from the Fourier transformed voxel time-series. "
      ],
      "metadata": {
        "id": "4SOogz4RXuUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "# This code is built to be versatile and allow to select \n",
        "# between all frequencies or only low and high ones\n",
        "##########################################################\n",
        "####################################################################\n",
        "# We are selecting only the first 2 subjects from the PIOP2 database\n",
        "# as a proof of concept for our study\n",
        "# But there are 226 subjects in the datasets available on openneuro.org PIOP2\n",
        "####################################################################\n",
        "\n",
        "# MULTI-SUBJECT ANALYSIS\n",
        "import os.path\n",
        "\n",
        "#allmat=[]\n",
        "highmat=[]\n",
        "lowmat=[]\n",
        "#Loop for chosen number of subjects\n",
        "for i in range(1,3): #Select number of subjects up to 226, here the first 2 only\n",
        "  key=\"sub-\"+str(i).zfill(4)\n",
        "# Download_file from openneuro.org\n",
        "  file_key = \"ds002790/derivatives/fmriprep/\"+key+\"/func/\"+key+\"_task-restingstate_acq-seq_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\"\n",
        "  client.download_file('openneuro.org', file_key, str(i)+'-resting.nii.gz')\n",
        "  img = image.load_img(str(i)+'-resting.nii.gz')\n",
        "  #Lists for collecting ICA results\n",
        "  #allfreq=[]  We are not taking correlation of all different frequencies to save computing time \n",
        "  lowfreq=[]\n",
        "  highfreq=[]\n",
        "\n",
        "#############################################\n",
        "#Loop for applying ICA masks and correlation\n",
        "#############################################\n",
        "\n",
        "  for icaf in [1,8]: #Picking only the 1 and 8 numbers from ICA results\n",
        "    icafile=str(icaf)+\"tstat.nii.gz\"\n",
        "    img_ica=image.load_img(icafile)\n",
        "    thr=min(heapq.nlargest(100,img_ica.get_fdata().flatten())) #Threshold for getting binary mask from top 100 voxels\n",
        "    #Creating masks, here 2 masks \n",
        "    xz,yz,zz=(np.where((img_ica.get_fdata())>=thr))\n",
        "    xm,ym,zm= np.transpose(get_mm_coord(img_ica,np.array([xz,yz,zz])))\n",
        "    x,y,z=np.transpose(get_volIdx(img,[xm,ym,zm]))\n",
        "    mean_img=image.mean_img(img)\n",
        "    nii_mask=build_mask_from_coord(mean_img,[x,y,z])\n",
        "\n",
        "###################################################################################    \n",
        "# Calculation of correlation for general, high, or low frequencies from masked data\n",
        "###################################################################################\n",
        "\n",
        "    masked_data = masking.apply_mask(imgs=img, mask_img= nii_mask)\n",
        "    length=masked_data.shape[1]\n",
        "    #matrix1=np.zeros((length,length)) \n",
        "    matrix2=np.zeros((length,length))\n",
        "    matrix3=np.zeros((length,length))\n",
        "    for mat1 in range(length):\n",
        "      for mat2 in range(length):\n",
        "        #matrix1[mat1][mat2]=corr(FFT(filt(masked_data[:,mat1]),'all'),FFT(filt(masked_data[:,mat2]),'all'))  Not taking correlation of all frequencies to save computing time \n",
        "        matrix2[mat1][mat2]=corr(FFT(filt(masked_data[:,mat1]),'high'),FFT(filt(masked_data[:,mat2]),'high'))\n",
        "        matrix3[mat1][mat2]=corr(FFT(filt(masked_data[:,mat1]),'low'),FFT(filt(masked_data[:,mat2]),'low'))\n",
        "    #allfreq.append(matrix1)\n",
        "    highfreq.append(matrix2)\n",
        "    lowfreq.append(matrix3)\n",
        "  #Appending to list for data from multiple subjects\n",
        "  #allmat.append(np.array(allfreq)) #only for all\n",
        "  highmat.append(np.array(highfreq))\n",
        "  lowmat.append(np.array(lowfreq))"
      ],
      "metadata": {
        "id": "XdX0a5-GgxHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d62108-d1c8-437f-8d09-9bde4980e2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:64: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting\n",
        "We plot the clustering of correlation matrices.\n",
        "\n",
        "Subject 1 - ICA component 1"
      ],
      "metadata": {
        "id": "LZoy6l8dX-8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################\n",
        "# Produce results using clustering graphics\n",
        "###############################################\n",
        "\n",
        "import seaborn as sns, numpy as np, matplotlib.pyplot as plt\n",
        "############################\n",
        "# 1 - Subject One Mask One\n",
        "############################\n",
        "sns.set_style(\"whitegrid\")\n",
        "g=sns.clustermap(highmat[0][0],cmap='mako',xticklabels=False) \n",
        "g.fig.suptitle('Correlation Matrix of High Frequencies (Subject 1, ICA 1)', size=22)\n",
        "h=sns.clustermap(lowmat[0][0],cmap='mako',xticklabels=False)\n",
        "h.fig.suptitle('Correlation Matrix of Low Frequencies (Subject 1, ICA 1)', size=22)\n",
        "\n"
      ],
      "metadata": {
        "id": "xOnB9GIlq81I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eighth ICA component"
      ],
      "metadata": {
        "id": "ld0LDpSw23WB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns, numpy as np, matplotlib.pyplot as plt\n",
        "\n",
        "############################\n",
        "# 2- Subject One Mask Eight\n",
        "############################\n",
        "sns.set_style(\"whitegrid\")\n",
        "g=sns.clustermap(highmat[0][1],cmap='mako',xticklabels=False) \n",
        "g.fig.suptitle('Correlation Matrix of High Frequencies (Subject 1, ICA 8)', size=22)\n",
        "h=sns.clustermap(lowmat[0][1],cmap='mako',xticklabels=False)\n",
        "h.fig.suptitle('Correlation Matrix of Low Frequencies (Subject 1, ICA 8)', size=22)"
      ],
      "metadata": {
        "id": "4z9hFMWO2qhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Subject 2**"
      ],
      "metadata": {
        "id": "E2OL225i1_0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# 3 - Subject Two Mask One\n",
        "############################\n",
        "\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "g=sns.clustermap(highmat[1][0],xticklabels=False) \n",
        "g.fig.suptitle('Correlation Matrix of High Frequencies (Subject 2, ICA 1)', size=22)\n",
        "h=sns.clustermap(lowmat[1][0],xticklabels=False)\n",
        "h.fig.suptitle('Correlation Matrix of Low Frequencies (Subject 2, ICA 1)', size=22)"
      ],
      "metadata": {
        "id": "3Qz0cvkH2Akr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eighth ICA component"
      ],
      "metadata": {
        "id": "U0jSZbkP26T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# 3 - Subject Two Mask Eight\n",
        "############################\n",
        "\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "g=sns.clustermap(highmat[1][1],xticklabels=False) \n",
        "g.fig.suptitle('Correlation Matrix of High Frequencies (Subject 2, ICA 8)', size=22)\n",
        "h=sns.clustermap(lowmat[1][1],xticklabels=False)\n",
        "h.fig.suptitle('Correlation Matrix of Low Frequencies (Subject 2, ICA 8)', size=22)"
      ],
      "metadata": {
        "id": "xSaZ4XQt2FXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix\n",
        "Extra code to illustrate the entire process for extracting the FFT of a voxel from the first subject."
      ],
      "metadata": {
        "id": "TxRVOROz5pFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################\n",
        "# Loading Resting State images found on AOMIC for subject 0001\n",
        "##############################################################\n",
        "\n",
        "#  Filter the data to include resting state only\n",
        "\n",
        "paginator = client.get_paginator('list_objects')\n",
        "\n",
        "operation_parameters = {'Bucket': 'openneuro.org',\n",
        "                        'Prefix': 'ds002790/derivatives/fmriprep/sub-0001/func'}\n",
        "\n",
        "result = paginator.paginate(**operation_parameters)\n",
        "filtered_iterator = result.search(\"Contents[?Key.contains(@,'task-restingstate')]\")\n",
        "task_list=[key_data['Key'] for key_data in filtered_iterator]\n",
        "# 2 - Use Panda library to select our files\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Use Panda library to split files\n",
        "files= np.array(task_list) #transform task list in np array np.array(task_list)\n",
        "# Generate a list using split\n",
        "filename_split = []\n",
        "for i in files:\n",
        "    filename_split.append(i[44:].split('_'))\n",
        "\n",
        "# make a panda Data Frame with filename  pd.DataFrame( filename_split)[5]\n",
        "pd_filename_list= pd.DataFrame(filename_split) \n",
        "# Run through all files with nii.gz endings\n",
        "nii_task=np.array([x.endswith('nii.gz') for x in task_list]) \n",
        "nii_files=np.asarray(task_list)[nii_task]\n",
        "pd.DataFrame([y.split(\"_\") for y in pd.DataFrame([x.split(\"/\") for x in  nii_files])[5] ])\n",
        "\n",
        "#######################################\n",
        "# Loading results of ICA files\n",
        "#######################################\n",
        "\n",
        "\n",
        "\n",
        "response = requests.get('https://neurovault.org/media/images/7104/comp-1_desc-dualreg_tstat.nii.gz')\n",
        "open('1tstat.nii.gz', \"wb\").write(response.content)\n",
        "\n",
        "icafile=\"0tstat.nii.gz\""
      ],
      "metadata": {
        "id": "fGHu0CYr5oZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_key=nii_files[4]\n",
        "\n",
        "import os.path\n",
        "\n",
        "# s3 client download_file\n",
        "if not  os.path.exists( \"resting.nii.gz\"):\n",
        "    client.download_file('openneuro.org', file_key, 'resting.nii.gz')"
      ],
      "metadata": {
        "id": "rV0SdbudDl60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img= image.load_img('resting.nii.gz')  # load your image with image.load_img\n",
        "print(img.get_data().shape)\n",
        "# launch interactive 3d view with view_img function\n",
        "plotting.view_img(image.index_img(img, 0))"
      ],
      "metadata": {
        "id": "KQjoLTYbDqMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "volume= img.get_fdata() # extract voil;ume data from image\n",
        "flat_slice=volume[1:,1:,30,0]\n",
        "plt.imshow(flat_slice, interpolation='nearest')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uk2r7ODbDyce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icafile=\"0tstat.nii.gz\"\n",
        "img_ica=image.load_img(icafile)\n",
        "print(img_ica.get_data().shape)"
      ],
      "metadata": {
        "id": "FkacnR4qEYpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#x,y,z=(np.unravel_index(np.argmax(img_zscore.get_data()),img_zscore.get_data().shape))\n",
        "\n",
        "# determine top 100 vx threshold :\n",
        "thr=min(heapq.nlargest(100,img_ica.get_data().flatten()))\n",
        "print(thr)\n",
        "xz,yz,zz=(np.where((img_ica.get_data())>=thr))\n",
        "#print(xz,yz,zz)\n",
        "xm,ym,zm= np.transpose(get_mm_coord(img_ica,np.array([xz,yz,zz])))\n",
        "#print(xm,ym,zm)\n",
        "x,y,z=np.transpose(get_volIdx(img,[xm,ym,zm]))\n",
        "#print(x,y,z)\n",
        "\n",
        "\n",
        "mean_img=image.mean_img(img)\n",
        "nii_mask=build_mask_from_coord(mean_img,[x,y,z])"
      ],
      "metadata": {
        "id": "TtTx6uBREYzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotting.view_img((img_ica),threshold=thr,resampling_interpolation=\"nearest\")"
      ],
      "metadata": {
        "id": "Zn7BAOt_EY5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotting.view_img(nii_mask,resampling_interpolation=\"nearest\")\n",
        "masked_data = masking.apply_mask(imgs=img, mask_img= nii_mask)\n",
        "masked_data.shape"
      ],
      "metadata": {
        "id": "entW7RthEY7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And now plot two time series\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.plot(masked_data[:, :2])\n",
        "plt.xlabel('Time [TRs]', fontsize=16)\n",
        "plt.ylabel('Intensity', fontsize=16)\n",
        "#plt.xlim(0, 150)\n",
        "plt.subplots_adjust(bottom=.12, top=.95, right=.95, left=.12)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VEL_rTXuEZGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.fft import fft,fftfreq\n",
        "from scipy.fftpack import fftshift\n",
        "from scipy.signal import spectrogram\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "ts=masked_data[:,0] ## example with 1 vx\n",
        "\n",
        "dt = 2#  use TR of the EPI acqisition\n",
        "fs = 1/dt\n",
        "\n",
        "# time vector\n",
        "time_vec= np.array(range(0,len(ts)*dt,dt))\n",
        "\n",
        "# Calculate the FFT\n",
        "L =masked_data.shape[0]# find out the number of acquisitions \n",
        "ax1=plt.subplot(311)\n",
        "plt.plot(time_vec, ts/ts.mean())#, label='bold signal at'+np.array2string([x,y,z]), linewidth=0.5)\n",
        "plt.ylabel('bold signal')\n",
        "plt.title('bold signal for 1 voxel')\n",
        "# Add title and labels\n",
        "plt.ylabel('stop task events')\n",
        "plt.xlabel('time in [s]')\n",
        "# Display plot\n",
        "plt.grid()\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(312, sharex=ax1)\n",
        "#plot windowed t/f analysis \n",
        "freqs, times, spectro = spectrogram( ts/ts.mean(),fs=fs, nperseg=3)\n",
        "plt.pcolormesh(times, fftshift(freqs), fftshift(spectro, axes=0), shading='gouraud')\n",
        "plt.ylabel('f [Hz]')\n",
        "plt.xlabel('t [sec]')\n",
        "#plt.yscale('symlog')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(313)\n",
        "N = 3*len(ts)//10 # number of FFT points (length of signal)\n",
        "#N=len(time_vec)\n",
        "Y2=fft(ts/ts.mean(),N)\n",
        "fv=fftfreq(N,dt)[:N//2]\n",
        "plt.stem(fv[1:N//2],2.0/N*np.abs(Y2[1:N//2]))\n",
        "plt.title(\"FFT\")\n",
        "plt.xlabel(\"Frequencey (Hz)\")\n",
        "plt.grid()\n",
        "\n",
        "# Auto space\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HEUKsiIBD2Px"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}